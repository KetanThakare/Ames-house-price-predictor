  import pandas as pd
  import numpy as np

#reading the csv file 
  ah_data = pd.read_csv("https://github.com/KetanThakare/ML-AmesHousePricePrediction/blob/master/AmesHousingData.csv")
  ah_data.sample(5)

#preprocessing the data
#missing values filtering
  missing_values_count = ah_data.isnull().sum()
  missing_values_count

#imputing missing value depending on the datatype of predictor 
#for integer datatype
  from sklearn.preprocessor import Imputer
  imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 'specify_axis')
  imputer = imputer.fit(x[int_columns])

#for categorical data
  from sklearn.base import TransformerMixin

 class CDImputer(TransformerMixin)

   def __init__ (self):
      """ Imputing missing values
          If the series is of dtype char then maximum occuring value will be imputed 
      """
   def fit(self, X, y=None):
    if   X[c].dtype == numpy.dtype('O'): self.fill = pd.Series(X[c].value_counts().index[0])
        return self

   def transform(self, X, y=None):
       return X.fillna(self.fill)

#dividing the predictors and response variable
  x = ah_data.iloc[:,-81]
  y = ah_data.iloc[:,81]

#hot encoding the categorical variables
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
  lenc = LabelEncoder()
  x[:, columnofcatpre] = lenc.x.fit_transform(x  [:,columnofcatpre]

oenc = OneHotEncoder(categorical_features =   [columnsofcatpre])
  x[:, columnofcatpre] = oenc.fit_transform(x).toarray


#Feature Selection
from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression #from sklearn.svm import SVR
#estimator = SVR(kernel = "linear")
model = LinearRegression()
rfe = RFE(estimator = model, n_features_to_select = 15)
fit = rfe.fit(x,y)
print("Num Features: %d") %fit.n_features_
print("Selected Features: %d") %fit.support_
print("Feature Ranking" %s") %fit_ranking_



 


